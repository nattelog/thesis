\chapter{Theory}
\label{cha:theory}

The theory framework is presented here. It has been developed mainly in the
initial phase of the study. Topics are presented here that are helpful for the
reader to get a grasp on the background of the methods and techniques used in
the study.

\section{Internet of Things}

The Internet of Things (IoT) is a relatively new paradigm of the internet where
not only people are interconnected, but \textit{everything} is. The term was
first heard in 1999 in a presentation by Kevin Ashton \cite{ashton2011internet}
and the popularity has since blossomed \cite{gubbi2013internet}. IoT can be
conceptualized as context-aware \textit{things} communicating with each other
and human-centered applications. The enabling applications are vast and include
domains from many areas of society - transportation, healthcare, homes, offices
and social domains to name a few. A good example is electricity consumption
control in homes. Electricity prices can be monitored and utilities such as
washing machines and heating can be optimized and only used when prices are low
\cite{atzori2010internet}. IoT can typically be explained as "one paradigm with
many visions" \cite{atzori2010internet} as there is no official definition of
the term. IoT is more than ubiquitous computing, embedded devices and
applications. It should not only be accessible by a small group of stakeholders
but embedded in today's open internet infrastructure. Referring to logistics an
IoT definition can be viewed as \textit{"[asking] for the right product in the
right quantity at the right time at the right place in the right condition and
at the right price"} \cite{uckelmann2011architectural}. Uckelmann et. al.
discusses these approaches and defines IoT as:

\begin{center}
\textit{"Internet of Things links
uniquely identifiable things to their virtual representations in the Internet
containing or linking to additional information on their identity, status,
location or any other business, social or privately relevant information at a
financial or non-financial pay-off that exceeds the efforts of information
provisioning and offers information access to non-predefined participants. The
provided accurate and appropriate information may be accessed in the right
quantity and condition, at the right time and place at the right price. The
Internet of Things is not synonymous with ubiquitous / pervasive computing, the
Internet Protocol (IP), communication technology, embedded devices, its
applications, the Internet of People or the Intranet / Extranet of Things, yet
it combines aspects and technologies of all of these approaches."}
\cite{uckelmann2011architectural}.
\end{center}

\subsection{Enabling technologies and challenges}

The state-of-the-art technologies used today in the IoT context include
sensoring equipment and networks such as the \textit{Radio Frequency
Identification} (RFID) and the \textit{Wireless Sensor Network} (WSN),
communication techniques like the \textit{IPv6 over Low-Power Wireless Personal
Area Network} (6LoWPAN) and \textit{Representational State Transfer} (REST) and
architectural approaches like \textit{middleware} and \textit{gateways}.

RFID is a technique used to identify an object by letting a reader generate an
electromagnetic wave which in turn generates a current in a microchip that
transmits a code back to the reader. The code, also known as an
\textit{Electronic Product Code} (EPC), can be used to identify the object. EPC
is developed by EPCglobal, a global non-profit organization, with the purpose
to spread the use of RFID and create global standards for modern businesses
\cite{atzori2010internet}. An RFID tag can be passive, i.e. work without
battery power, or active, i.e. work with battery power. It basically consists
of an antenna, a microchip attached to the antenna and some form of
encapsulation. They vary in size and shape; from centimeter long 3D-shaped
capsules to 2D-shaped stickers. The fact that they can work without a battery,
meaning they theoretically can work forever, make them very practical to use in
different environments. \cite{want2006introduction}

In a survey from 2001, Akyildiz et. al.  \cite{akyildiz2002wireless} presents a
\textit{Wireless Sensor Network} containing hardware nodes capable of
monitoring its environment and transmit the received data to a server or host
acting as a sink. The sensor could be one of many types and be able to measure
temperature, humidity, movement, lightning condition, noise levels etc. This
leads into one of the major challenges in IoT: communication and networking.
Following the semantical meaning of IoT, which states \textit{"[it is] a world
wide network of interconnected objects uniquely addressable, based on standard
communication protocols"} \cite{bassi2008internet}, it is clear that every node
will produce its own content and should be retrievable regardless of location.
This puts pressure on the identification methods and the overall network
infrastructure for IoT. As remaining unused IPv4 addresses are closing in to
zero, the IPv6 protocol can be a natural next step for IoT devices to use
\cite{atzori2010internet}. 4 bytes are used to address devices in IPv4, wich
means the protocol can support around 4 billion devices. IPv6 on the other hand
uses 16 bytes to address devices, meaning around $10^{38}$ devices can be
uniquely addressed.

6LoWPAN is a wireless technology suitable for resource-constrained nodes in the
IoT network. It is designed for small packet sizes, low bandwidth, low power
and low cost. It assumes a large amount of nodes will be deployed and that they
can be unreliable in terms of radio connectivity and power drain, thus making
this technology a good choice for wireless sensor nodes. \cite{kushalnagar2007ipv6}

\subsection{Gateways}

A big challenge in IoT is, as described earlier, to connect every single device
to the internet. For example, when devices in a WSN are deployed they do not
necessarily have the power and capacity to directly communicate to the
internet. A common approach to solve this problem is to add a gateway between
the devices and the internet, acting as an amplifier for the transmissions from
the devices \cite{zhu2010iot}. Chen et. al. \cite{chen2011brief} describes
three layers of domains in the IoT architecture: the \textit{sensing domain},
the \textit{network domain} and the \textit{application domain}. The sensing
domain is where the primitive communication between the actual devices in the
network happen; for instance RFID and 6LoWPAN. This domain is layered under the
network domain and each piece of information sent from the sensing domain is
aggregated, filtered and wrapped in the network domain before being sent to the
application domain. Note that the information protocols used between the
sensing- and network domain and the network- and application domain does not
necessarily match. As some protocols are more suited for resource-constrained
devices, they might require modification to be able to communicate with more
standardized protocols, like the \textit{Internet Protocol} (IP). For instance,
the EPC code generated by the RFID can not be put on an IP stack as is, but it
could be mapped to an IPv6 address via a gateway and thereby be identified and
usable through the internet \cite{lee2007epc}.

The gateways reside in the network domain. They act as a bridge between the
devices and the internet. The approaches towards implementing IoT gateways vary

\section{Event-driven architectures}

In software architecture, the terms \textit{event-driven}, or \textit{implicit
invocation}, are used to express the mechanism of function invocation based on
events \cite{garlan1993introduction}. In contrast, \textit{explicit invocation}
refers to a traditional function invocation by function name, e.g.
\lstinline{foo()}. However, a function can be mapped to an event so that when
the event occur, the function is invoked implicitly. Hence the name implicit
invocation. The announcers of events do not know what functions are registered
to the event and cannot make assumptions on event ordering or how data will be
transformed due to the event. This is one disadvantage of this architecture
\cite{garlan1993introduction}. However, in high-performance, I/O intensive
networking systems, it is shown that event-based approaches perform much better
\cite{hu1997measuring}.

\subsection{Task management and task management}
\label{sec:task-management}

A program task is an encapsulation of control flow with access to some common
shared state. This can be viewed as a closure in a program language or a
function. Managing these tasks can be done in several ways. In
\textit{preemptive} task management, tasks can be scheduled to interleave and
make room for other tasks or be run in parallell on multicore systems. In
\textit{serial} task management, tasks are run until they are finished before
any other task can start its execution. A hybrid approach is
\textit{cooperative} task management. Tasks can yield control to other tasks in
defined points in its execution. This is useful in I/O intensive systems where
tasks can make way for other tasks while waiting for I/O. Event-driven systems
usually implement the cooperative approach. Events, e.g.  network requests,
are handled by calling an associated function. A benefit with event-driven
systems that run on a single thread is that mutual exclusion conflicts never
occur. However, the state in which the task was in before yielding control to
another task is not necessarily the same as when the task resumes control.
\cite{adya2002cooperative}

There are two categories of I/O management: \textit{synchronous} and
\textit{asynchronous} \cite{adya2002cooperative}. If a function calls an I/O
operation and then blocks the rest of the execution while waiting for the I/O
operation to finish, the function is synchronous. Here is an example of a
synchronous read file-function from the Node.js documentation
\cite{nodejs-docs}:

\lstinputlisting[
  language=javascript,
  caption={Synchronous I/O example in Node.js.},
  label={listing:read_file_sync}
]{figures/read_file_sync.js}

The \lstinline{readFileSync()} function blocks the rest of the execution while
the file is being read, i.e. the file content will be printed before
\textit{"end of code"}. In asynchronous I/O, the function calling the I/O
operation returns immediately but is provided a function to be run when the I/O
is ready. Here is an equivalent implementation but with an asynchronous
function:

\lstinputlisting[
  language=javascript,
  caption={Asynchronous I/O example in Node.js.},
  label={listing:read_file_async}
]{figures/read_file_async.js}

\lstinline{readFile()} does not in this case return anything, but instead let
the event handling system invoke the callback function when the I/O is ready.
The execution continues directly, so \textit{"end of code"} will be printed
before the file content.

An interesting notice to Listing \ref{listing:read_file_async} is that, say a
global state is introduced and is dependent upon by the callback function,
there is no guarantee the state remains unchanged between the
\lstinline{readFile()}- and the \lstinline{callback()}-invocation. This is
similar to the mutual exclusion problem in preemeptive task management where
multiple agents wants to access the same resource concurrently, and problems
like read/write conflicts can occur. But since cooperative task management not
necessarily infer multithreaded environments, concurrent problems can be
avoided. There are however other problems related to understanding and
scalability of the code. In Listing \ref{listing:read_file_sync} one can
observe that all operations happen in the same scope. This is called
\textit{automatic stack management} and it means the task is written as a
single procedure with synchronous I/O \cite{adya2002cooperative}. The current
state of the program is always kept in the local stack and there is no
possibility it can be mutated by other parties. In \textit{manual stack
management} the task is ripped into callbacks, or \textit{event handlers},
which are registered to the event handling system. This can have a negative
impact on the control flow and the global state of the program as tasks are
being broken into functions with separate scopes.

\section{Reactive systems}

Systems required to continually respond to its environment are called
\textit{reactive} systems. Harel and Pnueli \cite{harel1985development}
elaborates on different system dichotomies, for instance deterministic and
nondeterministic systems. Deterministic systems have unique actions which
always generates the same output. Nondeterministic systems do not have that
property and it can cause them to be more difficult to handle. Another
dichotomy is sequential and concurrent systems. Concurrent systems cause
problems which are easily avoidable in sequential ones. For instance the mutual
exclusion problem where it is not always trivial what process owns what
resource and whether it is safe to modify a resource that can be used by
another process. A more fundamental dichotomy is presented by Harel and Pnueli:
\textit{transformational} and \textit{reactive} systems. A transformational
system transforms its input and creates new output. It can continually prompt
for new input. A reactive system is prompted the other way around: from the
outside. It does not necessarily compute any input, but it maintains a
relationship with its outside environment. A reactive system can be
deterministic or nondeterministic, sequential or concurrent, thus making the
transformational/reactive system dichotomy a fundamental system paradigm.
\cite{harel1985development}

\subsection{Specifications for reactive systems}

Harel and Pnueli presents a method for decomposing complex system using
\textit{statecharts}. Drawn from the theories of \textit{finite state
automata}, a system can be expressed using states. This is particularily useful
for reactive systems that can react to a large amount of different inputs. One
powerful feature with statecharts is its ability to handle hierarchical states.
If a system has a numerous amount of input combinations, a large set of states
must be created which in the long run is not appropiate in terms of
scalability. One solution to this is hierarchical states in which a state can
hold a number of other states. Fundamentally, a state undergo a transition to
another state when an action is performed on that state.
\cite{harel1985development}

Ardis et al. \cite{ardis1996framework} created a specification for a telephone
switching system which later was tested on a number of languages. They started
by describing some general properties of the system in a list. In general, the
list had the format:

\begin{enumerate}
\item
  When event $X_1$ occurs,
\begin{enumerate}
\item
  If some condition or property of the system holds true, call action $Y_1$
\item
  Otherwise, call action $Z_1$
\end{enumerate}

\item
  When event $X_2$ occurs,
\begin{enumerate}
\item
  Call action $Y_2$
\end{enumerate}

\item
  And so on...
\end{enumerate}

They then implemented a system fullfilling the requirements in a set of
different languages. Most languages fit well for reactive systems since their
semanticS allows and makes it easy to build and define different state
machines.  They also did one implementation in C in which they had two
solutions: one using arrays to hold all the different actions and states and
one using switch-blocks.

However, specification of primitive components can still be a challenge.
Non-trivial steps might be required to transition from one state to another.
Hummel and Thyssen \cite{hummel2009behavioral} presents a formal method to
specify a reactive system using stream based I/O-tables. In addition to
generating a simple and understandable description of the system, the method
helps formalize inconsistent requirements.

\section{Reactive programming}

Reactive programming has been proposed to be the solution to implement
event-driven architectures \cite{bainomugisha2013survey}. It is derived from
the \textit{Synchronous Data Flow} (SDF) paradigm \cite{lee1987synchronous}.
SDF is a data flow abstraction used to describe parallell computation.
Functions are presented as nodes in a directed graph and the arcs represent
data paths. Nodes can execute its computation whenever data is available on its
incoming arcs, and nodes with no incoming arcs can execute at any time. This
leads to concurrency since multiple nodes can execute in the same time. One
constraint on this system is that of \textit{side-effects}, which are not
allowed. Nodes cannot mutate any resource accessible by another node unless
they are explicitly connected by an arc.

In the reactive programming paradigm, the notion of time is abstracted away. In
the same way memory can be abstracted away by garbage collection in languages
like Java, the programmer does not have to instruct the program \textit{when}
things will execute, but rather \textit{how} \cite{bainomugisha2013survey}.
Data dependencies and change propagation can be handled automatically by the
language. Consider a simple example:

\begin{lstlisting}[language=C]
int i = 1;
int j = 1;
int k = i + j;
\end{lstlisting}

In a language like C, $k$ will be computed to the value $2$. If $i$ later on is
redefined to another value, say $3$, $k$ will still hold the same value $2$. In
a reactive setting, $k$ will be updated with the latest value of either $i$ or
$j$, even if they change later on in time. It can be viewed such that $k$ is
\textit{dependent} on $i$ and $j$. \cite{bainomugisha2013survey}

Reactive programming has two distinguishing features: \textit{behaviors} and
\textit{events}. Behaviors refer to time-varying values, e.g. time itself.
Events on the other hand, happen in discrete points in time and describes what
happened. This could be a file that is ready to be written to, a network
request that is available or a keyboard button that was pressed.
\cite{bainomugisha2013survey}

\subsection{A taxonomy}

Bainomugisha et al. \cite{bainomugisha2013survey} presents a taxonomy with six
fundamental properties considered important features in reactive languages.

\subsubsection{Basic abstractions}

Imperative languages holds basic abstractions in the form of primitives such as
primitive operators and values. Reactive languages holds basic abstractions
such as behaviors and events.

\subsubsection{Evaluation model}
\label{sec:evaluation-model}

When an event occurs, the evaluation model of a reactive language determines
how change is propagated throughout the data dependencies. Propagatation can
either be \textit{push-based}, meaning that data is pushed to its dependencies
as soon as an event occur, or \textit{pull-based}, meaning that computation
nodes pull data when needed. The former is a \textit{data driven} model and is
often implemented using callbacks. A challenge is to find out what nodes do not
need to be recomputed. The pull-based model is said to be \textit{demand
driven} as data is propagated upon request. A disadvantage with this model is
that delays between events and reactions can be long.

\subsubsection{Glitch avoidance}

A \textit{glitch} is when inconsistencies in the data occur due to the way
updates are propagated among the dependencies. Consider the following example:

\begin{lstlisting}[language=C]
int i = j;
int k = i + j;
\end{lstlisting}

$k$ is dependent on $i$ and $j$ and $i$ is on another level dependent on
$j$. If $j$ is updated, the case can be that $k$ is updated before $i$, thus
leading to an inconsistency between $k$ and $i$. Here is an example:


\begin{lstlisting}[language=C]
// j == 1
int i = j;      // i == 1
int k = i + j;  // k == 2

// j == 2, k updated before i
int i = j;      // i == 1
int k = i + j;  // k == 3, should be 4
\end{lstlisting}

These kinds of inconsistencies, or glitches, should be avoided by the language.

\subsubsection{Lifting operators}

\textit{Lifting} in reactive programming refers to the act of making previously
uncompliant operators or functions work with behaviors. Lifting transforms the
type signature of the function and registers the topology of its dependencies
in the dataflow graph. A function $f$ with a non-behavior type $T$ can be
lifted as:

\begin{lstlisting}
f(T) -> flift(Behavior<T>)
\end{lstlisting}

Where $Behavior$ is a behavior-type holding a type $T$. In Flapjax, an reactive
language built upon Javascript, lifting is performed on multiple places to
support behaviors \cite{meyerovich2009flapjax}. Here is an example from the
language:

\begin{lstlisting}[language=javascript]
let time = timerB(1000);
\end{lstlisting}

This looks like traditional, imperative Javascript. However, $timerB$ with the
argument $1000$ starts a timer that yields every second and $time$ will always
be kept up to date with the yielded value. Flapjax performs lifting on, among
others, the addition ($+$) operator:


\begin{lstlisting}[language=javascript]
let time = timerB(1000) + 1;
\end{lstlisting}

The compiler transforms the expression using the $liftB$ function, looking
somewhat like this:

\begin{lstlisting}[language=javascript]
liftB(function(t) { return t + 1 }, timerB(1000));
\end{lstlisting}

This is called \textit{implicit lifting}, meaning that the programmer does not
have to worry about whether the add operator was used on a behavior or not
\cite{bainomugisha2013survey}.

\subsubsection{Multidirectionality}

A property of reactive languages is to support data propagation both from
derived data, as well as the data it is derived from. Consider a distance
converting function:

\begin{lstlisting}[language=C]
double miles = km * 1.61;
\end{lstlisting}

Whenever an updated value on either $miles$ or $km$ is available, the other one
is recalculated as well.

\subsubsection{Support for distribution}

As interactive applications such that web applications are becoming more
popular (whose nature is distributed) it is important for reactive languages to
also support distributed mechanisms.

\section{Choosing programming language for embedded systems}

In embedded systems programming, both hardware and software is important. Nahas
and Maaita \cite{nahas2012choosing} mention a few factors to be considered when
choosing a programming language for an embedded system:

\begin{itemize}
\item
  The language must take the resource constraints of an embedded processor
  into account
\item
  It must allow low-level access to the hardware
\item
  It must be able to re-use code components in the form of libraries from other
    projects
\item
  It must be a widely used language with good access to documentation and other
    skilled programmers
\end{itemize}

There is no scientific method for selecting an appropiate language for a
specific project. Selection mostly relies on experience and subjective
assessment from developers. It was however shown in 2006 that over 50 \% of
embedded system projects were developed in C and 30 \% were developed in C++.
Barr \cite{barr1999programming} states that the key advantage of C is that it
allows the developer to access hardware without loosing the benefits of
high-level programming. Compared to C, C++ offer a better object-oriented
programming style but can on the other hand be less efficient.
\cite{nahas2012choosing}

\section{libuv}

libuv is an asynchronous I/O cross-platform library written in C. It is one of
the major core systems of Node.js, a popular JavaScript runtime engine. libuv's
central part is the single-threaded event loop which contains all I/O
operations. The event loop notifies any I/O events in a callback fashion using
abstractions called \textit{handles} and \textit{requests}. Handles are
long-lived structures and are operated on using requests. Requests usually only
represent one I/O operation on a handle. Each I/O operation performed on the
event loop is \textit{non-blocking}, meaning they instantly return and
abstracts away any concurrency necessary. To handle network I/O libuv makes use
of platform specific functionality, such as \textit{epoll} for Linux. For file
I/O libuv utilizes its \textit{thread pool} to make the operation non-blocking.
All loops can queue work in this thread pool making it ideal for external
services or systems that do not want to block any I/O. libuv includes handles
for \textit{UDP} and \textit{TCP} sockets, file and file system, \textit{TTY},
timers and \textit{child processes}. \cite{libuv-docs}

\begin{figure}[h!]
\centering
    \caption[The libuv event loop.]{The stages each event loop iteration steps
    through in libuv.}
    \label{fig:loop_iteration}
    \begin{tikzpicture}[node distance=1.5cm, auto]
        \node [block] (loop_time) {Update loop time};
        \node [decision, below of=loop_time] (alive) {Loop alive?};
        \node [block, left of=alive, node distance=3cm] (end) {End};
        \node [block, below of=alive, node distance=2.5cm] (run_due) {Run due timers};
        \node [block, below of=run_due] (pending) {Call pending callbacks};
        \node [block, below of=pending] (idle) {Run idle callbacks};
        \node [block, below of=idle] (prepare) {Run prepare handles};
        \node [block, below of=prepare] (poll) {Poll for I/O};
        \node [block, below of=poll] (check) {Run check handles};
        \node [block, below of=check] (close) {Call close callbacks};

        \path [line] (loop_time) -- (alive);
        \path [line] (alive) -- node {No} (end);
        \path [line] (alive) -- node {Yes} (run_due);
        \path [line] (close.east) -- ++(1cm,0) |- (loop_time.east);
    \end{tikzpicture}
\end{figure}

Figure \ref{fig:loop_iteration} demonstrates the stages each event loop
iteration steps through. A loop is considered to be alive if there are any
active handles or requests. For instance, if a TCP socket is closing its
connection the handle structure is freed from the heap and both the request and
handle are no longer active. If they were the last being active the loop dies.
The steps are described briefly: \cite{libuv-docs}

\begin{enumerate}
  \item The loop time is updated and stored for the entire iteration.
  \item If the loop is alive the iteration starts, otherwise it dies.
  \item All active timers who are scheduled to timeout have their callbacks
    called.
  \item Pending callbacks are called; they are I/O callbacks deferred from the previous
    iteration.
  \item Callbacks registered for idle handles are called. Idle handles are good
    for low priority activity.
  \item Callbacks that should be called right before polling for I/O can be
    registered with prepare handles, whose callbacks are called here.
  \item The time to poll for I/O is calculated here. It either blocks for 0
    seconds, the timeout for the closest timer or infinity. Depending on
    whether there are active idle handles or requests or if the loop is about
    to close, the time is 0. \label{item:poll_time_calculation}
  \item I/O is polled and the loop is blocked. All handles monitoring I/O will
    have their callbacks called.
  \item Callbacks that should be called right after polling for I/O can be
    registered with check handles, whose callbacks are called here.
  \item Handles being closed have their close callbacks called.
  \item If the loop was configured to only run once and no I/O callbacks were
    called after the poll, timers might be due since time could have elapsed
    during the poll. Those timers gets their callbacks called.
  \item Depending on the loop's configuration and if it is still alive, the
    loop exits or continues.
\end{enumerate}

The following example provided by Marathe \cite{uvbook} shows an idle handler
and its corresponding callback. As seen in Figure \ref{fig:loop_iteration} and
explained in step \ref{item:poll_time_calculation} idle handles and their
callbacks are called every iteration with 0 poll time.

\lstinputlisting[
  language=C,
  caption={libuv example with an idle handle \cite{uvbook}.},
  label={listing:idle_handle}
]{figures/libuv_idle_handle_example.c}

libuv includes a number of data types and functions which can be found in its
documentation \cite{libuv-docs}.

\section{Software testing}

Testing software is a broad concept with many goals such as validating an
implementation to conform to its specification, evaluating robustness and
performance, or finding inconsistencies in the design
\cite{bertolino2007software}. It is a generally hierarchical process where the
discrete modules (\textit{unit testing}) to the interaction between modules
(\textit{integration testing}) to the composition of modules and the entire
system (\textit{system testing}) is tested \cite{raymond1998automatic}. The
specification of the \textit{system under test} (SUT) can be unknown, thus only
the inputs and the outputs of the system can be examined for test case
generation (\textit{black-box testing}) \cite{jorgensen2016software}. The
codebase of the SUT can also be known, enabling verification of test case
coverage so all paths in the code are tested (\textit{white-box testing})
\cite{jorgensen2016software}.

Software testing includes basic terms such as \textit{error}, \textit{fault},
\textit{failure}, \textit{incident}, \textit{test} and \textit{test case}
\cite{radatz1990ieee}. Errors and faults share the same meaning, a good synonym
is \textit{bug}. But an error is something a human does (verb) and a fault is
the expressive representation of the error. When a program executes a fault a
failure occurs. But the failure could have happened not only because bad code
was executed (\textit{faults of commission}) - it could also be due to the fact
that the correct code was abscent (\textit{faults of omission}). An incident is
the consequence of a failure that signals the user of its presence.
Fundamentally the act of testing has two objectives: to locate failures and to
verify correct execution of the program. The actual procedure that executes a
test is the test case and it has a set of inputs and a set of expected outputs.
\cite{jorgensen2016software}

Important to ask oneself when tests are being planned or about to be carried
out is \cite{bertolino2007software}:

\begin{itemize}
  \item What is the \textit{test objective}? To locate faults in the design or
    verify correct behavior?
  \item What test methods should be \textit{selected}?
  \item What is an \textit{adequate} test sample? What is the criteria to stop
    testing?
  \item What \textit{levels} of testing should be conducted? Unit testing on
    separate modules or the entire system?
  \item In what environment should the tests be conducted?
  \item When should the tests be conducted? In the end of the software
    lifecycle in a waterfall fashion, or continuously between sprints in an
    agile development framework?
\end{itemize}

\subsection{Performance testing}

Performance testing is the process of measuring and evaluating certain
performance related benchmarks in a system; usually by putting the system under
I/O load such as simulated network traffic \cite{jiang2015survey}. Software
systems contain resources such as the CPU, processes, threads and I/O that all
have limited capacities, which mean they potentially can deny each others
execution when several users require the same resource. Analysing a system's
performance requires quantification of such effects \cite{woodside2007future}.
The goal of the tests could be to compare an existing system with a new
proposed system to see which one performs better \cite{avritzer1996deriving} or
to, in an early phase of the development of a system, identify future
performance problems upon deliverance \cite{weyuker2000experience}. Contrary to
functional software testing where the values of the test inputs determines the
test outcome, performance testing emphasizes the \textit{workloads} and
\textit{frequencies} of the inputs \cite{weyuker2000experience}. Jiang and
Hassan discusses performance testing along with two other similar testing
techniques: \textit{load testing} and \textit{stress testing}
\cite{jiang2015survey}. Load testing is defined as the process of assessing a
system's behavior under load to find both functional and non-functional related
issues. Stress testing is about putting the system under extreme load
conditions to verify robustness.  Performance testing differ from the other two
when it comes to verification of benchmarks. A performance test can for
instance happen when a module has been reengineered and the performance must be
verified to at least be as good as the previous version of the module
\cite{jiang2015survey}.

Usually, performance tests objectives relate to I/O throughput and response
time. Weyuker and Vokolos conducted performance tests on a telecommunication
gateway by developing simulated telephone callers \cite{weyuker2000experience}.
These callers performed calls and transactions on the systems that were
measured to analyse performance. Performance metrics used by the popular
performance testing tool \textit{JMeter}\footnote{See
\url{jmeter.apache.org}.}, which is often used to test web applications and
services, include \cite{mendelawy2016kpis}:

\begin{description}
  \item[Number of Users:] Measuring the number of active users can be done by
    creating \textit{virtual users} in a testing program. This metric is at
    most interesting when analysed together with Hits per Second.
  \item[Hits per Second:] This is a measure on how many requests are generated
    by each user. The correlation between Number of Users and Hits per Second
    provides a valuable hint on the performance of the server.
  \item[Errors per Second:] A high error rate when the user amount increases
    indicates a performance issue.
  \item[Response Time:] The time it takes from a request to its response is,
    especially when multiple requests are fired concurrently, a good indication
    on the performance of the system.
  \item[Throughput:] This measures the average bandwidth usage generated by the
    tests.
\end{description}

To conduct a performance test, not only are the metrics necessary, but a
representative workload is needed as well \cite{weyuker2000experience}.
Methods to design workloads often requires historical data on what load the
system undergoes in typical usage. But as performance testing usually is
performed on novel systems, historical data is a rare commodity
\cite{barber2004creating}. Alternative approaches can be to retrieve usage data
from a beta version of the system, have interviews with domain experts or
analyse usage data from competitors \cite{jiang2015survey}. Barber synthesizes
common approaches found in the industry and provides a, somewhat agile,
framework to support design of a workload model where historical data is
incomplete or unavailable \cite{barber2004creating}:

\begin{enumerate}
  \item Identify existing historical data, preferably found in log files from
    production instances of the system.
  \item If log files are unavailable, try to extract information from
    stakeholders such as salesmen (they might know of the most anticipated
    activities that can be used in the workload design) and users (they might
    know what activites they probably will do).
  \item Look for performance related activites in design and requirements
    documents.
  \item Whenever a new beta version of the system is available, retrieve
    workload data from it.
  \item Look for workload data in competitors' statistics if available.
  \item Conduct in-house experiments.
  \item If no data is available, use personal experience as a substitute to
    design an appropiate model.
  \item Create visual representations of the model for peer review.
  \item Create three different workload models based on:
    \begin{enumerate}
      \item Anticipated or expected usage.
      \item Best case usage.
      \item Worst case usage.
    \end{enumerate}
\end{enumerate}

Jiang and Hassan suggests workload models can either reflect the system's
performance requirements (so called \textit{aggregate-workload based load
design}) or the system's expected usage (\textit{use-case based load design}).
An example of a performance requirement can be that CPU usage should not exceed
90 \% when 10,000 transactions are concurrently handled. Expected usage can be,
for a web shop application, that users typically spend 40 \% of their time
browsing and 60 \% in the checkout. In the aggregate-workload approach loads
are characterized as the \textit{workload intensity}, i.e. the rate in which
the requests fire, and the \textit{workload mix}, which describes the different
kinds of requests in the workload, e.g. 20 \% of the requests come from
resource $A$ and 80 \% from resource $B$. For cases where historical data or an
operational profile is available, a workload model can be designed as
\textit{steady load} or \textit{step-wise load}. In a steady load, only one
intensity and mix configuration is used, normally to represent expected usage
of the system. However, a better representation of a realistic workload would
be one where the workload varies with time. A step-wise load include multiple
levels of workload intensity (but keeps the workload mix) to mimic certain
usage levels across a time period. The main disadvantage with the
aggregate-workload approach is that loads can be unrealistic or hard to design.
The use-case approach tries to solve this by introducing states and stochastic
aspects into the design. One can for instance design loads using \textit{use-case
diagrams}, \textit{Markov chains} and \textit{Probabilistic Timed Automata} to
create usage driven designs that resemble real-world workloads. \cite{jiang2015survey}

\section{Software development methodology}

There exists a numerous amount of ways to develop software. In plan-based
methodologies, including the \textit{waterfall model}, the way of working is
highly inspired by traditional engineering such as manufacturing and
construction. Given a set of phases in the development, each phase must be done
before the next phase starts. These phases include \textit{requirement
definition}, \textit{design}, \textit{implementation}, \textit{testing} and
\textit{release} \cite{crookshanks2014practical}. On the other end of the
spectra lies the \textit{agile} methodologies. Initially developed as a
response to the frustration of the static, slow-going process of the well-used
waterfall model, it is based on the understanding that software requirements
are highly dynamic and most certainly change over time
\cite{moniruzzaman2013comparative}.

Vijayasarathy and Butler \cite{vijayasarathy2016choice} found in an online
survey they conducted in 2016 that around a third of all software projects were
using the waterfall model as main software methodology. Following were the
agile methodologies \textit{Agile Unified Process} and \textit{Scrum}. They
also found that multiple methodologies were often used in the same project.
For instance the agile method \textit{Joint Application Development} was used
in one project to identify requirements, while the waterfall model was used in
the remainder of the project.

\subsection{Scrum}

Scrum is an agile framework utilized by small teams to develop both simple and
complex products. Scrum is not only used to do software development, it can be
applied to any development - even writing a book \cite{sims2012scrum}. In Scrum
there are three main components: \textit{roles}, \textit{artifacts} and
\textit{the sprint cycle}. Roles are taken by people in the team, artifacts are
tools used by the team and the fundamental pulse of the project is the sprint
cycle. Three distinct roles are recognized: \textit{product owner},
\textit{Scrum master} and \textit{team member}. The product owner is the team's
representation of the \textit{stakeholders} of the product (mainly the business
related stakeholders). He is responsible for making the team always do most
valuable work, he holds the vision of the product, he owns the \textit{product
backlog} and creates acceptance criteria for the backlog items. The scrum
master is the team's coach guiding them to become a high-performing,
self-organizing team. He helps the team apply and shape the agile practices to
the team's advantage. A team member is responsible for completing \textit{user
stories}, create \textit{estimates} and decides what tools to use in the
upcoming \textit{sprint}. \cite{sims2012scrum}

The artifacts recognized by Scrum are called \textit{product backlog},
\textit{sprint backlog}, \textit{burn down charts} and \textit{task board}. The
product backlog consists of a list of deliverables that can be anything of
value for the product, e.g. features and documentation changes. Items in the
list are also called \textit{user stories} and they are ordered by priority.
They include information such as who the story is for, what needs to be built,
how much work is needed to implement it and what the acceptance criteria is.
Prior to a \textit{sprint}, user stories are derived into practical
\textit{tasks} usually performed by a single team member. The sprint backlog is
populated by these tasks and they are expected to be finished within the time
limit of the sprint. To monitor the status of the sprint or the entire project,
the burn down chart is used. It is a diagram showing how much work is left to
be done.  The Y-axis shows the amount of tasks and the X-axis the time. As time
progress the amount of tasks are hopefully decreasing. The task board is used
to help the team inspect their current situation. It usually consists of three
columns: \textit{To do}, \textit{Doing} and \textit{Done}. Each column consists
of tasks (or symbols of tasks) in the current sprint, and gives the team a
visual on what tasks are yet to be done. \cite{sims2012scrum}

A Scrum project is split into a series of sprints. They are time limited
smaller versions of the entire project where a pre-defined amount of tasks are
to be completed within the sprint. When a sprint is finished a potentially
working product is demonstrated. The benefit of short-lived sprints is that the
team receives frequent feedback on their work, giving them a better presumption
to improve future sprints. From a business perspective, the sprint method
provides greater freedom to decide if a product should be shipped or further
developed. A sprint consists of a number of meetings: \textit{sprint planning},
\textit{daily Scrum}, \textit{story time}, \textit{sprint review} and
\textit{retrospective}. A sprint always starts with a sprint planning. It is a
meeting where the product owner and the team decides which user stories will be
a part of the sprint backlog in the upcoming sprint. This is also where the
team derive the user stories into tasks. Every day the team also has brief
daily Scrum meetings. Each team member shares what tasks they completed since
the previous meeting, what tasks they expect to complete before the next and
what difficulties they are currently facing. Every week, during story time, the
product backlog is again reviewed by the team and the product owner. This time
each user story is evaluated to refine its acceptance criteria. If there are
large stories in the backlog they are also split into smaller stories to make
them easier to understand and easier to complete within a sprint. The sprint
review marks the public end of the sprint. Here the completed user stories are
demonstrated to the stakeholders and feedback is received. After this meeting
the team has a retrospective meeting where they discuss what strategy changes
can be made to improve the next sprint. \cite{sims2012scrum}

