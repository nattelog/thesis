\chapter{Theory}
\label{cha:theory}

Theories used in this study are presented here. They include software metrics,
electronic hardware metrics, previous research on event-driven-related
architectures and some general information regarding C++ and the \textit{libuv}
library.

\section{Reactive systems}

Systems required to continually respond to its environment are called
\textit{reactive} systems. Harel and Pnueli \cite{harel1985development}
elaborates on different system dichotomies, for instance deterministic and
nondeterministic systems. Deterministic systems have unique actions which
always generates the same output. Nondeterministic systems do not have that
property and it can cause them to be more difficult to handle. Another
dichotomy is the sequential and concurrent systems. Concurrent systems cause
problems which are easily avoidable in sequential ones. For instance the mutual
exclusion problem where it is not always trivial what process owns what
resource and whether it is safe to modify a resource that can be used by
another process. A more fundamental dichotomy is presented by Harel and Pnueli:
\textit{transformational} and \textit{reactive} systems. A transformational
system transforms its input and creates new output. It can continually prompt
for new input. A reactive system is prompted the other way around: from the
outside. It does not necessarily compute any input, but it maintains a
relationship with its outside environment. A reactive system can be
deterministic or nondeterministic, sequential or concurrent, thus making the
transformational/reactive system dichotomy a fundamental system paradigm.
\cite{harel1985development}

\section{Programming embedded systems}

In embedded systems programming, both hardware and software is important. Nahas
and Maaita \cite{nahas2012choosing} mentiones a few factors to be considered
when choosing a programming language for an embedded system:

\begin{itemize}
\item
  The language must take the resource constraints of an embedded processor
  into account
\item
  It must allow low-level access to the hardware
\item
  It must be able to re-use code components in the form of libraries from other
    projects
\item
  It must be a widely used language with good access to documentation and other
    skilled programmers
\end{itemize}

There is no scientific method for selecting an appropiate language for a
specific project. Selection mostly relies on experience and subjective
assessment from developers. It was however shown in 2006 that over 50 \% of
embedded system projects were developed in C and 30 \% were developed in C++.
Barr \cite{barr1999programming} states that the key advantage of C is that it
allows the developer to access hardware without loosing the benefits of
high-level programming. Compared to C, C++ offer a better object-oriented
programming style but can on the other hand be less efficient.
\cite{nahas2012choosing}

\section{Multithreading}

Multithreading can be achieved both in software and in hardware. In software,
multithreading is achieved by the operating system. Each process corresponds to
a thread and each process can also spawn new threads
\cite{silberschatz2014operating}.

The component maintaining all these threads is called the \textit{scheduler}
and its main purpose is to balance the load of threads between the CPU cores.
The big problems the scheduler faces is 1) to make sure the most important
thread is currently running and 2) to minimize the number of context switches,
i.e. switching the current working thread. Linux uses a scheduling algorithm
called \textit{Completely Fair Scheduling} (CFS) which, in a single-core
context, is quite simple. However, for multi-core systems the algorithm has
proven to get very complex and several bugs has been found in it.
\cite{lozi2016linux}

\section{Software metrics}

In all engineering fields, measurement is important. Measuring software is a
way for an engineer to assess its quality and a large number of software
metrics have been derived during the years \cite{aggarwal2006empirical}.

Previous research show that software process improvements is key for both large
and small successful companies. However, it requires a balance between formal
process and informal practice. Large companies tend to lean more towards the
formality of things and employees are given less space to be creative. On the
other hand, small companies tend to do the opposite: employees are given
freedom to explore solutions while formal processes are being put aside. Dyb√•
\cite{dybaa2003factors} suggests that "formal processes must be supplemented
with informal, inter-personal coordination about practice". It is also
important to note how failure is handled. Failure is essential for improving
learning and questioning the status quo inside both companies and software. If
failure is unacceptable, the organizational competance can decrease when facing
change in the environment. When a company is successful it will grow larger
with repeated success and there is no financial reason to change what already
works and generates revenue. However, eventually when the environment changes
there might be good reasons to dust off legacy systems and introduce some new
patches. The cost of doing so might depend on whether the system was initially
built with maintenability in mind. \cite{dybaa2003factors}

\subsection{Maintainability}

Maintainability can be measured in many ways. Aggarwal et al.
\cite{aggarwal2006empirical} suggests that some metric results can be derived
from others. In the same way the area and diagonal can be derived from the
width and height of a table, some metrics may provide redundant information.
Oman and Hagemeister \cite{oman1992metrics} proposes a quantitative approach
where multiple metrics can be combined into a unified value. Software
maintainability can be divided into three broad categories:

\begin{itemize}
\item The management practices being employed
\item Hardware and software environments involved in the target software system
\item The target software system
\end{itemize}

Oman and Hagemeister further derive the target software system into additional
categories:

\begin{itemize}
\item Maturity attributes
\item Source code
\item Supporting Documentation
\end{itemize}

Maturity attributes include metrics such as the \textit{age} of the software
since release, \textit{size} in terms of non-commented source statements and
\textit{reliability} which can be measured as the rate of failures per hour.
Source code include metrics on how the software is decomposed into algorithms
and how they are implemented, e.g. the number of modules and the cyclomatic
complexity averaged over all modules. It also includes metrics on the
information flow in the system, e.g. the number of global data types and
structures, the number of data structures whose type is converted and the
number of lines of code dedicated to I/O. Coding style metrics are also
included, e.g. the percentage of uncrowded statements (only one statement per
line), the number of blank lines and the number of commented lines are taken
into account. Supporting documentation are evaluated in a subjective manner.
Metrics include traceability to and from code implementation, verifiability of
the implementation and consistency of the writing style and comprehensibility
of the document. \cite{oman1992metrics}

To assess these metrics, Oman and Hagemeister introduces a formula:

$$
\prod_{i=1}^m{W_D_i(\frac{\sum_{j=1}^n{W_A_jM_A_j}}{n})_i}
$$

where $W_D_i$ is the weight of influence of software maintainability category
$D_i$, e.g.  source code control structure. $W_A_j$ is the weight of influence
of maintainability attribute $A_j$, e.g. software age. $M_A_j$ is the measure
of maintainability attribute $A_j$. The values should be structured so that
they range from 0 to 1, thereby showing a percentage of their correctness.
Worth noting is that not all attributes have to be measured, only those of
significant value.

\subsection{Measuring maintainability in C++}

Some metrics might not be suitable for object-oriented (OO) languages and C++
in particular. Wilde and Huitt \cite{wilde1991maintenance} studies some of the
main difficulties regarding maintenance as in "post deployment support" of
OO-languages. These languages introduces the concepts of \textit{object class
inheritance hierarchy} and \textit{polymorphism} which in some sense helps give
programmers a better understanding of their programs, but the maintenance
burden will unlikely disappear completely. One issue with analyzing OO source
code is \textit{dynamic binding}. An object variable might not necessarily
refer to its declared class type, but it can also refer to any of its
descendants in the class hierarchy. This makes static analysis complicated,
e.g. it is not always known what implementation of a method will be used when
the method is called on an object.

Rajaraman and Lyu \cite{rajaraman1992reliability} have also studied the
shortcomings on some traditional maintainability metrics on OO-languages. For
instance, they look on the metric \textit{statement count} which can predict a
software's complexity. It is built on the assumption that "the more detail that
an entity possesses, the more difficult it is to understand"
\cite{rajaraman1992reliability}. The metric simply counts the number of
statements in a program or module. They criticize the metric for not taking the
program's context into account and that it is not easy to determine what
exactly a statement is. They also criticize McCabe's
\cite{mccabe1976complexity} \textit{cyclomatic complexity measure} that
calculates a program's complexity by taking the number of edges in a program
flow graph, the number of nodes and the number of connected components into
account (nodes are abstractions of sequential blocks of code and edges are
conditional branches in the program). The critique involves, as stated earlier
regarding statement count, that the metric ignores the context in the program
and has no support to take the complexity of each statement into account.

Rajaraman and Lyu \cite{rajaraman1992reliability} defines four measures of
\textit{coupling} in their paper. They define the term coupling as "[...] a
measure of association, whether by inheritance or otherwise, between classes in
a software product". Abstracting the program to a directed multigraph, each
node represents a class and each edge represents a reference from one node to
another through variable references and method calls. Two of the proposed
measures, \textit{Class Coupling} and \textit{Average Method Coupling} resulted
in highest correlation (though not statistically significant) with perceived
maintainability when tested on a number of C++ programs. Class Coupling for a
class $C$ is defined as the sum of each outgoing edge from $C$; i.e. the sum of
all global variable references, all global function uses, all calls to other
class methods and all local references to other class instances. Average Method
Coupling is a ratio number between a class $C$'s Class Coupling and its total
number of methods, i.e. $AMC = CC / n$ where $n$ is the total number of methods
declared in $C$.

\section{Hardware performance metrics}
